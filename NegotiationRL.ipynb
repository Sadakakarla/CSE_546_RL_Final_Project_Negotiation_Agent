{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NegotiableAI: Enabling Agents to Negotiate Deals using Multi-Agent Reinforcement Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submitted by:\n",
    "Sada Kakarla - 50605634 - sadakaka\n",
    "<br> Shivansh Gupta - 50604127 - sgupta67\n",
    "<br> Aditi Sinha - 50593917 - asinha25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "from gymnasium import spaces \n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RL-Driven Automated Buyer-Seller Negotiations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simulates a buyer–seller interaction environment over a fixed number of rounds & observes the rewards received by each agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Negotiation_Agent(gym.Env):\n",
    "    def __init__(self, seller_min_amt, max_rounds=20, initial_selling_price=None, \n",
    "                 gamma_seller=1.0, gamma_buyer=1.0, shaping_lambda=1.0):\n",
    "    \n",
    "        super(Negotiation_Agent, self).__init__()\n",
    "        self.max_rounds = max_rounds\n",
    "        self.seller_min_amt = seller_min_amt\n",
    "        if initial_selling_price is None:\n",
    "            \n",
    "            initial_selling_price = np.random.randint(2000, 10000)\n",
    "        self.initial_selling_price = initial_selling_price\n",
    "        self.gamma_seller = gamma_seller\n",
    "        self.gamma_buyer = gamma_buyer\n",
    "        self.shaping_lambda = shaping_lambda\n",
    "        \n",
    "        # Observation space: [current_offer, round, turn, deal_status]\n",
    "        low = np.array([seller_min_amt, 0, 0, 0], dtype=np.float32)\n",
    "        high = np.array([self.initial_selling_price, max_rounds, 1, 1], dtype=np.float32)\n",
    "        self.observation_space = spaces.Box(low=low, high=high, dtype=np.float32)\n",
    "        \n",
    "\n",
    "        # Accept: 1, Reject: 2, Counteroffer: (\"Counteroffer\", new_price)\n",
    "        self.action_space = spaces.Discrete(3)  \n",
    "        \n",
    "    def reset(self):\n",
    "        self.round = 0\n",
    "        \n",
    "        # Start at the target price/ initial selling price\n",
    "        self.current_offer = self.initial_selling_price\n",
    "        \n",
    "        # Record seller's last counteroffer\n",
    "        self.last_seller_offer = self.initial_selling_price\n",
    "        \n",
    "        # Initialize buyer's last counteroffer to None\n",
    "        self.last_buyer_offer = None\n",
    "        \n",
    "        self.turn = 0  # 0: Buyer and 1: Seller\n",
    "        self.deal_status = False\n",
    "        return self.get_observation()\n",
    "    \n",
    "    def _buyer_potential(self, offer):\n",
    "        return (self.initial_selling_price - offer) / (self.initial_selling_price - self.seller_min_amt)\n",
    "    \n",
    "    def _seller_potential(self, offer):\n",
    "        return (offer - self.seller_min_amt) / (self.initial_selling_price - self.seller_min_amt)\n",
    "    \n",
    "    def step(self, action):\n",
    "        done = False\n",
    "        info = {}\n",
    "        reward = {'buyer': 0, 'seller': 0}\n",
    "        \n",
    "        if self.round >= self.max_rounds:\n",
    "            done = True\n",
    "            reward['buyer'] = -10\n",
    "            reward['seller'] = -10  \n",
    "            return self.get_observation(), reward, done, info\n",
    "        \n",
    "        # Accept action: negotiation ends\n",
    "        if action == 1:\n",
    "            print(f\"Seller accepts the offer\")\n",
    "            done = True\n",
    "            self.deal_status = True\n",
    "            final_price = self.current_offer\n",
    "            max_margin = self.initial_selling_price - self.seller_min_amt\n",
    "            if max_margin == 0:\n",
    "                max_margin = 1\n",
    "            seller_profit_norm = (final_price - self.seller_min_amt) / max_margin\n",
    "            buyer_savings_norm = (self.initial_selling_price - final_price) / max_margin\n",
    "            reward['seller'] = self.gamma_seller * seller_profit_norm\n",
    "            reward['buyer']  = self.gamma_buyer * buyer_savings_norm\n",
    "            \n",
    "        elif action == 2:\n",
    "            # Reject action: negotiation ends with a penalty\n",
    "            done = True\n",
    "            reward['buyer'] = -5\n",
    "            reward['seller'] = -5\n",
    "            \n",
    "        elif isinstance(action, tuple) and action[0] == \"Counteroffer\":\n",
    "            new_offer = action[1]\n",
    "            if self.turn == 0:\n",
    "                \n",
    "                # Buyer’s counteroffer: must be strictly lower than current_offer and not below seller_min_amt.\n",
    "                # If buyer has already made a counteroffer, the new offer must be >= last buyer offer.\n",
    "                \n",
    "                if new_offer >= self.current_offer or new_offer < self.seller_min_amt:\n",
    "                    reward['buyer'] = -3\n",
    "                elif self.last_buyer_offer is not None and new_offer < self.last_buyer_offer:\n",
    "                    \n",
    "                    # Enforcing non-decreasing buyer counteroffers\n",
    "                    reward['buyer'] = -3\n",
    "                else:\n",
    "                    self.current_offer = new_offer\n",
    "                    self.last_buyer_offer = new_offer\n",
    "                    self.turn = 1  # Pass turn to seller.\n",
    "                    reward['buyer'] = -1\n",
    "                    reward['seller'] = -1\n",
    "                    self.round += 1\n",
    "            elif self.turn == 1:\n",
    "                # Seller’s counteroffer must be higher than buyer's counteroffer and cannot exceed his previous (last_seller_offer)\n",
    "                \n",
    "                if new_offer <= self.current_offer or new_offer > self.last_seller_offer:\n",
    "                    reward['seller'] = -3\n",
    "                else:\n",
    "                    self.current_offer = new_offer\n",
    "                    self.last_seller_offer = new_offer  # update seller's last counteroffer\n",
    "                    self.turn = 0  # Pass turn to buyer\n",
    "                    reward['buyer'] = -1\n",
    "                    reward['seller'] = -1\n",
    "                    self.round += 1\n",
    "        else:\n",
    "            reward['buyer'] = -2\n",
    "            reward['seller'] = -2\n",
    "        \n",
    "        if self.round >= self.max_rounds:\n",
    "            done = True\n",
    "            reward['buyer'] = -10\n",
    "            reward['seller'] = -20\n",
    "        \n",
    "        return self.get_observation(), reward, done, info\n",
    "    \n",
    "    def get_observation(self):\n",
    "        return np.array([self.current_offer, self.round, self.turn, int(self.deal_status)], dtype=np.float32)\n",
    "    \n",
    "    def render(self, mode='human'):\n",
    "        turn_str = \"Buyer\" if self.turn == 0 else \"Seller\"\n",
    "        print(f\"Round: {self.round}, Turn: {turn_str}, Current Offer: {self.current_offer}, Deal Status: {self.deal_status}\")\n",
    "\n",
    "\n",
    "# Automated the buyer and seller policies for self-play.\n",
    "def buyer_policy(state, env):\n",
    "    # The buyer's goal is to lower the price\n",
    "    current_offer = int(state[0])\n",
    "    if current_offer - env.seller_min_amt <= 10:\n",
    "        return 1  # accept\n",
    "    if env.last_buyer_offer is None:\n",
    "        new_price = np.random.randint(env.seller_min_amt, current_offer)\n",
    "    else:\n",
    "        new_price = np.random.randint(env.last_buyer_offer, current_offer)\n",
    "    return (\"Counteroffer\", new_price)\n",
    "\n",
    "def seller_policy(state, env):\n",
    "    current_offer = int(state[0])\n",
    "    last_offer = int(env.last_seller_offer)\n",
    "    if last_offer - current_offer <= 10:\n",
    "        return 1  # Accept if the gap is too small\n",
    "    if current_offer >= last_offer:\n",
    "        return 2  # Invalid move\n",
    "    new_price = np.random.randint(current_offer+1, last_offer+1)\n",
    "    return (\"Counteroffer\", new_price)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Selling Price: 997\n",
      "Round: 0, Turn: Buyer, Current Offer: 997, Deal Status: False\n",
      "Buyer action: ('Counteroffer', 924)\n",
      "Round: 1, Turn: Seller, Current Offer: 924, Deal Status: False\n",
      "Reward: {'buyer': -1, 'seller': -1}\n",
      "Seller action: ('Counteroffer', 982)\n",
      "Round: 2, Turn: Buyer, Current Offer: 982, Deal Status: False\n",
      "Reward: {'buyer': -1, 'seller': -1}\n",
      "Buyer action: ('Counteroffer', 944)\n",
      "Round: 3, Turn: Seller, Current Offer: 944, Deal Status: False\n",
      "Reward: {'buyer': -1, 'seller': -1}\n",
      "Seller action: ('Counteroffer', 966)\n",
      "Round: 4, Turn: Buyer, Current Offer: 966, Deal Status: False\n",
      "Reward: {'buyer': -1, 'seller': -1}\n",
      "Buyer action: ('Counteroffer', 959)\n",
      "Round: 5, Turn: Seller, Current Offer: 959, Deal Status: False\n",
      "Reward: {'buyer': -1, 'seller': -1}\n",
      "Seller action: 1\n",
      "Seller accepts the offer\n",
      "Round: 5, Turn: Seller, Current Offer: 959, Deal Status: True\n",
      "Reward: {'buyer': 0.12794612794612795, 'seller': 0.8720538720538721}\n",
      "Negotiation ended.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    # Generating a random initial selling price between 800 and 1000.\n",
    "    random_initial_price = np.random.randint(800, 1000)\n",
    "    print(f\"Initial Selling Price: {random_initial_price}\")\n",
    "    \n",
    "    Negotiation_RL_Agent_env = Negotiation_Agent(seller_min_amt=700, max_rounds=20, initial_selling_price=random_initial_price,\n",
    "                                   gamma_seller=1.0, gamma_buyer=1.0, shaping_lambda=1.0)\n",
    "    \n",
    "    state = Negotiation_RL_Agent_env.reset()\n",
    "    Negotiation_RL_Agent_env.render()\n",
    "    \n",
    "    done = False\n",
    "    \n",
    "    # Self-play loop: Both buyer and seller act in an automated manner\n",
    "    while not done:\n",
    "        if state[2] == 0:\n",
    "            action = buyer_policy(state, Negotiation_RL_Agent_env)\n",
    "            print(f\"Buyer action: {action}\")\n",
    "        else:\n",
    "            action = seller_policy(state, Negotiation_RL_Agent_env)\n",
    "            print(f\"Seller action: {action}\")\n",
    "        \n",
    "        state, reward, done, info = Negotiation_RL_Agent_env.step(action)\n",
    "        Negotiation_RL_Agent_env.render()\n",
    "        print(\"Reward:\", reward)\n",
    "    \n",
    "    print(\"Negotiation ended.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the Negotiation Agent by performing random actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Negotiation_Random_Agent(gym.Env):\n",
    "    def __init__(self, seller_min_amt, max_rounds=20, initial_selling_price=None, \n",
    "                 gamma_seller=1.0, gamma_buyer=1.0, shaping_lambda=1.0):\n",
    "        \n",
    "        super(Negotiation_Random_Agent, self).__init__()\n",
    "        self.max_rounds = max_rounds\n",
    "        self.seller_min_amt = seller_min_amt\n",
    "        if initial_selling_price is None:\n",
    "        \n",
    "            initial_selling_price = np.random.randint(2000, 10000)\n",
    "        self.initial_selling_price = initial_selling_price\n",
    "        self.gamma_seller = gamma_seller\n",
    "        self.gamma_buyer = gamma_buyer\n",
    "        \n",
    "        # Observation space: [current_offer, round, turn, deal_status]\n",
    "        low = np.array([seller_min_amt, 0, 0, 0], dtype=np.float32)\n",
    "        high = np.array([self.initial_selling_price, max_rounds, 1, 1], dtype=np.float32)\n",
    "        self.observation_space = spaces.Box(low=low, high=high, dtype=np.float32)\n",
    "        \n",
    "        # Accept: 1, Reject: 2, Counteroffer: (0, new_price)\n",
    "        self.action_space = spaces.Discrete(3)  \n",
    "        self.shaping_lambda = shaping_lambda\n",
    "        \n",
    "    def reset(self):\n",
    "        self.round = 0\n",
    "\n",
    "        self.current_offer = self.initial_selling_price\n",
    "        # Record seller's last counteroffer \n",
    "        self.last_seller_offer = self.initial_selling_price\n",
    "        self.turn = 0  # 0: Buyer, 1: Seller.\n",
    "        self.deal_status = False\n",
    "        return self.get_observation()\n",
    "    \n",
    "    def _buyer_potential(self, offer):\n",
    "        # Normalized potential for buyer: higher is better for buyer\n",
    "        return (self.initial_selling_price - offer) / (self.initial_selling_price - self.seller_min_amt)\n",
    "    \n",
    "    def _seller_potential(self, offer):\n",
    "        # Normalized potential for seller: higher is better for seller\n",
    "        return (offer - self.seller_min_amt) / (self.initial_selling_price - self.seller_min_amt)\n",
    "    \n",
    "    \n",
    "    def step(self, action):\n",
    "        done = False\n",
    "        info = {}\n",
    "        reward = {'buyer': 0, 'seller': 0}\n",
    "        \n",
    "        if self.round >= self.max_rounds:\n",
    "            done = True\n",
    "            reward['buyer'] = -10\n",
    "            reward['seller'] = -10  \n",
    "            return self.get_observation(), reward, done, info\n",
    "        \n",
    "        # Accept action: negotiation ends\n",
    "        if action == 1:\n",
    "            done = True\n",
    "            self.deal_status = True\n",
    "            final_price = self.current_offer\n",
    "            \n",
    "            max_margin = self.initial_selling_price - self.seller_min_amt\n",
    "    \n",
    "            if max_margin == 0:\n",
    "                max_margin = 1\n",
    "            seller_profit_norm = (final_price - self.seller_min_amt) / max_margin\n",
    "            buyer_savings_norm = (self.initial_selling_price - final_price) / max_margin\n",
    "            reward['seller'] = self.gamma_seller * seller_profit_norm\n",
    "            reward['buyer']  = self.gamma_buyer * buyer_savings_norm\n",
    "            \n",
    "        # Reject action: negotiation ends with penalty.\n",
    "        elif action == 2:\n",
    "            done = True\n",
    "            reward['buyer'] = -5\n",
    "            reward['seller'] = -5\n",
    "        \n",
    "        \n",
    "        # Counteroffer action: action is a tuple (0, new_price)\n",
    "        # elif isinstance(action, tuple) and action[0] == 0:\n",
    "        elif isinstance(action, tuple) and (action[0] == 0 or action[0] == \"Counteroffer\"):\n",
    "\n",
    "            new_offer = action[1]\n",
    "            if self.turn == 0:\n",
    "                # Buyer’s counteroffer: must be strictly lower than current_offer and not below seller_min_amt.\n",
    "                if new_offer >= self.current_offer or new_offer < self.seller_min_amt:\n",
    "                    reward['buyer'] = -3  # invalid counteroffer by buyer.\n",
    "                else:\n",
    "                    self.current_offer = new_offer\n",
    "                    self.turn = 1  # Pass turn to seller\n",
    "                    reward['buyer'] = -1\n",
    "                    reward['seller'] = -1\n",
    "                    self.round += 1\n",
    "            elif self.turn == 1:\n",
    "                # Seller’s counteroffer: must be strictly higher than buyer's current counteroffer & cannot exceed his previous (last_seller_offer)\n",
    "                if new_offer <= self.current_offer or new_offer > self.last_seller_offer:\n",
    "                    reward['seller'] = -3  # invalid seller counteroffer.\n",
    "                else:\n",
    "                    self.current_offer = new_offer\n",
    "                    self.last_seller_offer = new_offer  # update seller's last counteroffer\n",
    "                    self.turn = 0  # Pass turn to buyer\n",
    "                    reward['buyer'] = -1\n",
    "                    reward['seller'] = -1\n",
    "                    self.round += 1\n",
    "        else:\n",
    "            reward['buyer'] = -2\n",
    "            reward['seller'] = -2\n",
    "        \n",
    "        \n",
    "        if self.round >= self.max_rounds:\n",
    "            done = True\n",
    "            reward['buyer'] = -10\n",
    "            reward['seller'] = -20\n",
    "        \n",
    "        return self.get_observation(), reward, done, info\n",
    "    \n",
    "    def get_observation(self):\n",
    "        return np.array([self.current_offer, self.round, self.turn, int(self.deal_status)], dtype=np.float32)\n",
    "    \n",
    "    def render(self, mode='human'):\n",
    "        turn_str = \"Buyer\" if self.turn == 0 else \"Seller\"\n",
    "        print(f\"Round: {self.round}, Turn: {turn_str}, Current Offer: {self.current_offer}, Deal Status: {self.deal_status}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Case (i) When the buyer accepts the current offer without any negotiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Selling Price: 828\n",
      "Round: 0, Turn: Buyer, Current Offer: 828, Deal Status: False\n",
      "Round: 0, Turn: Buyer, Current Offer: 828, Deal Status: True\n",
      "Reward: {'buyer': 0.0, 'seller': 1.0}\n",
      "Negotiation ended.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Generate a random initial selling price between 1000 and 5000.\n",
    "    random_initial_price = np.random.randint(800, 1000)\n",
    "    print(f\"Initial Selling Price: {random_initial_price}\")\n",
    "\n",
    "    Negotiation_RL_Random_Agent_env = Negotiation_Random_Agent(seller_min_amt=700, max_rounds=20, initial_selling_price=random_initial_price,\n",
    "                     gamma_seller=1.0, gamma_buyer=1.0)\n",
    "    \n",
    "    state = Negotiation_RL_Random_Agent_env.reset()\n",
    "    Negotiation_RL_Random_Agent_env.render()\n",
    "    \n",
    "    human_buyer_mode = True  # Buyer is controlled manually by human input\n",
    "    done = False\n",
    "    \n",
    "    while not done:\n",
    "        if state[2] == 0 and human_buyer_mode:\n",
    "            inp = input(\"Buyer - Enter action: accept (1), reject (2), or counteroffer (0 new_price): \")\n",
    "            parts = inp.strip().split()\n",
    "            if parts[0] == \"0\":\n",
    "                if len(parts) < 2:\n",
    "                    print(\"Please provide a new price for your counteroffer.\")\n",
    "                    continue\n",
    "                try:\n",
    "                    new_price = int(float(parts[1]))\n",
    "                except:\n",
    "                    print(\"Invalid price. Try again.\")\n",
    "                    continue\n",
    "                action = (0, new_price)\n",
    "            elif parts[0] in [\"1\", \"2\"]:\n",
    "                action = int(parts[0])\n",
    "            else:\n",
    "                print(\"Invalid input. Try again.\")\n",
    "                continue\n",
    "        else:\n",
    "            if state[2] == 1:\n",
    "                delta = 10\n",
    "                low_bound = int(state[0]) + 1\n",
    "                proposed_offer = Negotiation_RL_Random_Agent_env.last_seller_offer - np.random.randint(1, delta+1)\n",
    "                new_price = max(low_bound, proposed_offer)\n",
    "                new_price = min(new_price, Negotiation_RL_Random_Agent_env.last_seller_offer)\n",
    "                print(f\"Seller proposes counteroffer: {new_price}\")\n",
    "            else:\n",
    "                action = Negotiation_RL_Random_Agent_env.action_space.sample()\n",
    "        \n",
    "        state, reward, done, info = Negotiation_RL_Random_Agent_env.step(action)\n",
    "        Negotiation_RL_Random_Agent_env.render()\n",
    "        print(\"Reward:\", reward)\n",
    "    \n",
    "    print(\"Negotiation ended.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Case (ii) When the buyer rejects the current offer without any negotiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Selling Price: 972\n",
      "Round: 0, Turn: Buyer, Current Offer: 972, Deal Status: False\n",
      "Round: 0, Turn: Buyer, Current Offer: 972, Deal Status: False\n",
      "Reward: {'buyer': -5, 'seller': -5}\n",
      "Negotiation ended.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Generate a random initial selling price between 1000 and 5000.\n",
    "    random_initial_price = np.random.randint(800, 1000)\n",
    "    print(f\"Initial Selling Price: {random_initial_price}\")\n",
    "\n",
    "    Negotiation_RL_Random_Agent_env = Negotiation_Random_Agent(seller_min_amt=700, max_rounds=20, initial_selling_price=random_initial_price,\n",
    "                     gamma_seller=1.0, gamma_buyer=1.0)\n",
    "    \n",
    "    state = Negotiation_RL_Random_Agent_env.reset()\n",
    "    Negotiation_RL_Random_Agent_env.render()\n",
    "    \n",
    "    human_buyer_mode = True  # Buyer is controlled manually by human input\n",
    "    done = False\n",
    "    \n",
    "    while not done:\n",
    "        if state[2] == 0 and human_buyer_mode:\n",
    "            inp = input(\"Buyer - Enter action: accept (1), reject (2), or counteroffer (0 new_price): \")\n",
    "            parts = inp.strip().split()\n",
    "            if parts[0] == \"0\":\n",
    "                if len(parts) < 2:\n",
    "                    print(\"Please provide a new price for your counteroffer.\")\n",
    "                    continue\n",
    "                try:\n",
    "                    new_price = int(float(parts[1]))\n",
    "                except:\n",
    "                    print(\"Invalid price. Try again.\")\n",
    "                    continue\n",
    "                action = (0, new_price)\n",
    "            elif parts[0] in [\"1\", \"2\"]:\n",
    "                action = int(parts[0])\n",
    "            else:\n",
    "                print(\"Invalid input. Try again.\")\n",
    "                continue\n",
    "        else:\n",
    "            if state[2] == 1:\n",
    "                delta = 10\n",
    "                low_bound = int(state[0]) + 1\n",
    "                proposed_offer = Negotiation_RL_Random_Agent_env.last_seller_offer - np.random.randint(1, delta+1)\n",
    "                new_price = max(low_bound, proposed_offer)\n",
    "                new_price = min(new_price, Negotiation_RL_Random_Agent_env.last_seller_offer)\n",
    "                print(f\"Seller proposes counteroffer: {new_price}\")\n",
    "            else:\n",
    "                action = Negotiation_RL_Random_Agent_env.action_space.sample()\n",
    "        \n",
    "        state, reward, done, info = Negotiation_RL_Random_Agent_env.step(action)\n",
    "        Negotiation_RL_Random_Agent_env.render()\n",
    "        print(\"Reward:\", reward)\n",
    "    \n",
    "    print(\"Negotiation ended.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Case (iii) When the buyer counteroffers the seller's price through negotiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Selling Price: 850\n",
      "Round: 0, Turn: Buyer, Current Offer: 850, Deal Status: False\n",
      "Round: 1, Turn: Seller, Current Offer: 750, Deal Status: False\n",
      "Reward: {'buyer': -1, 'seller': -1}\n",
      "Seller proposes counteroffer: 848\n",
      "Round: 2, Turn: Buyer, Current Offer: 848, Deal Status: False\n",
      "Reward: {'buyer': -1, 'seller': -1}\n",
      "Round: 3, Turn: Seller, Current Offer: 780, Deal Status: False\n",
      "Reward: {'buyer': -1, 'seller': -1}\n",
      "Seller proposes counteroffer: 840\n",
      "Round: 4, Turn: Buyer, Current Offer: 840, Deal Status: False\n",
      "Reward: {'buyer': -1, 'seller': -1}\n",
      "Round: 5, Turn: Seller, Current Offer: 800, Deal Status: False\n",
      "Reward: {'buyer': -1, 'seller': -1}\n",
      "Seller proposes counteroffer: 837\n",
      "Round: 6, Turn: Buyer, Current Offer: 837, Deal Status: False\n",
      "Reward: {'buyer': -1, 'seller': -1}\n",
      "Round: 7, Turn: Seller, Current Offer: 820, Deal Status: False\n",
      "Reward: {'buyer': -1, 'seller': -1}\n",
      "Seller proposes counteroffer: 836\n",
      "Round: 8, Turn: Buyer, Current Offer: 836, Deal Status: False\n",
      "Reward: {'buyer': -1, 'seller': -1}\n",
      "Round: 9, Turn: Seller, Current Offer: 830, Deal Status: False\n",
      "Reward: {'buyer': -1, 'seller': -1}\n",
      "Seller proposes counteroffer: 831\n",
      "Round: 10, Turn: Buyer, Current Offer: 831, Deal Status: False\n",
      "Reward: {'buyer': -1, 'seller': -1}\n",
      "Round: 10, Turn: Buyer, Current Offer: 831, Deal Status: True\n",
      "Reward: {'buyer': 0.12666666666666668, 'seller': 0.8733333333333333}\n",
      "Negotiation ended.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Generate a random initial selling price between 1000 and 5000.\n",
    "    random_initial_price = np.random.randint(800, 1000)\n",
    "    print(f\"Initial Selling Price: {random_initial_price}\")\n",
    "\n",
    "    Negotiation_RL_Random_Agent_env = Negotiation_Random_Agent(seller_min_amt=700, max_rounds=20, initial_selling_price=random_initial_price,\n",
    "                     gamma_seller=1.0, gamma_buyer=1.0)\n",
    "    \n",
    "    state = Negotiation_RL_Random_Agent_env.reset()\n",
    "    Negotiation_RL_Random_Agent_env.render()\n",
    "    \n",
    "    human_buyer_mode = True  # Buyer is controlled manually by human input\n",
    "    done = False\n",
    "    \n",
    "    while not done:\n",
    "        if state[2] == 0 and human_buyer_mode:\n",
    "            inp = input(\"Buyer - Enter action: accept (1), reject (2), or counteroffer (0 new_price): \")\n",
    "            parts = inp.strip().split()\n",
    "            if parts[0] == \"0\":\n",
    "                if len(parts) < 2:\n",
    "                    print(\"Please provide a new price for your counteroffer.\")\n",
    "                    continue\n",
    "                try:\n",
    "                    new_price = int(float(parts[1]))\n",
    "                except:\n",
    "                    print(\"Invalid price. Try again.\")\n",
    "                    continue\n",
    "                action = (0, new_price)\n",
    "            elif parts[0] in [\"1\", \"2\"]:\n",
    "                action = int(parts[0])\n",
    "            else:\n",
    "                print(\"Invalid input. Try again.\")\n",
    "                continue\n",
    "        else:\n",
    "            if state[2] == 1:\n",
    "                delta = 10\n",
    "                low_bound = int(state[0]) + 1\n",
    "                proposed_offer = Negotiation_RL_Random_Agent_env.last_seller_offer - np.random.randint(1, delta+1)\n",
    "                new_price = max(low_bound, proposed_offer)\n",
    "                new_price = min(new_price, Negotiation_RL_Random_Agent_env.last_seller_offer)\n",
    "                action = (\"Counteroffer\", new_price)\n",
    "                print(f\"Seller proposes counteroffer: {new_price}\")\n",
    "            else:\n",
    "                action = Negotiation_RL_Random_Agent_env.action_space.sample()\n",
    "        \n",
    "        state, reward, done, info = Negotiation_RL_Random_Agent_env.step(action)\n",
    "        Negotiation_RL_Random_Agent_env.render()\n",
    "        print(\"Reward:\", reward)\n",
    "    \n",
    "    print(\"Negotiation ended.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### As we can see in the above negotiation, the seller proposes 831 towards the end of the rounds and the buyer accepts it, and the reward received by the seller (seller reward = 0.8733) is higher than the buyer (buyer reward = 0.1266)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
